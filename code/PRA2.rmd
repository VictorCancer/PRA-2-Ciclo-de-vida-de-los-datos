---
title: '**Práctica 2 - Limpieza y análisis de datos**'
author: "Maria Dolores Moyano Guerrero y Victor Cancer Castillo"
date: "25 de Mayo de 2022"
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    includes:
      in_header: logouoc.html
    toc: yes
    toc_float: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,message=FALSE,warning=FALSE,results='hide',quietly = TRUE,include=FALSE}
library(ggplot2)
library(corrplot)
library(faraway)
library(ggfortify)
library(ResourceSelection)
library(pROC)
library(grid)
library(colorspace)
library(Rcpp)
library(vctrs)
library(tidyverse)
library(VIM)
library(ggpubr)
library(caTools)

```

------------------------------------------------------------------------

<font size="26"> **Titanic: Machine Learning from Disaster** </font>

------------------------------------------------------------------------

# Descripción del dataset

El desastre del RMS Titanic fue un accidente marítimo que acaeció en el 1912 y que se llevó por delante más de 1500 vidas. A bordo del Titanic iban más de 2000 pasajeros, por lo que cerca del 75% de los pasajerons fallecieron en el hundimiento del barco el cual no tenia botes salvavidas para todos los pasajeros.

Estas muertes no se dieron por igual para todos los grupos de pasajeros de manera aleatoria, sino que parece ser que hubo grupos dentro del barco que tuvieron más probabilidad de morir que otros, como podremos ver en este estudio.

Nos vamos a centrar aquí en tratar de averiguar qué características compartían en común los pasajeros que se salvaron/fallecieron para tratar de crear un modelo que sea capaz de predecir si un pasajero iba a morir o no.

# Integración y selección de los datos

Para tratar este problema vamos a utilizar los datos que se ofrecen en la competicción de [Kaggle](https://www.kaggle.com/competitions/titanic/overview), donde se da un dataset que contiene datos para entrenar el modelo y otro para hacer los tests del modelo creado.

Por un lado tenemos los datos para entrenar el modelo

```{r}
train <- read.table(file="train.csv",sep=',',dec='.',stringsAsFactors = TRUE,header=TRUE)
summary(train)
```

Y por otro tenemos los datos para testear dicho modelo

```{r}
test <- read.table(file="test.csv",sep=',',dec='.',stringsAsFactors = TRUE,header=TRUE)
summary(test)
```

Las variables que incluye el dataset son las siguientes:

-   *PassengerId*: Número de identificación del pasajero
-   *Survived*: Indica si el pasajero sobrevivió (0 = No, 1 = Sí)
-   *Pclass*: Clase de tiquet (1 = Primera clase, 2 = Segunda clase, 3 = Tercera clase)
-   *Name*: Nombre del pasajero
-   *Sex*: Sexo del pasajero
-   *Age*: Edad del pasajero
-   *SibSp*: Número de hermanos/hermanas, esposos/esposas a bordo del Titanic
-   *Parch*: Número de padres/madres, hijos/hijas a bordo del Titanic
-   *Ticket*: Número de ticket
-   *Fare*: Tarifa del pasajero
-   *Cabin*: Número de cabina
-   *Embarked*: Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton)

Para hacer análisis (no modelaje) trataremos los datos completos (es decir los datos de test y de entrenamiento, sin la columna *Survived*)

```{r}
full <- rbind(test,train[-which(names(train) == "Survived")])
```

# Limpieza de los datos

En primer lugar, vamos a estudiar si los datos tienen elementos vacíos

## Elementos nulos o ceros

### Embarked

Vemos entre los valores de la columna Embarked del dataset de entrenamiento que hay dos valores vacíos

```{r}
full[full$Embarked == "",]
```

Probablemente la relación más relevante entre el puerto de embarque la tiene el precio del billete (pues al hacer un viaje más largo se cobrará más al pasajero). Por lo tanto veamos con qué puerto encajan más estas dos pasajeras sabiendo que ellas pagaron 80\$ por su billete de primera clase:

```{r}
ggplot(full[full$Embarked != "" & full$Pclass == "1",],aes(x=Embarked,y=Fare, fill=Embarked)) + geom_boxplot()+
    theme(legend.position="none") + geom_hline(aes(yintercept=80), colour='yellow', linetype='dashed', lwd=2)

```

De esta gráfica podemos deducir que estas mujeres probablemente embarcaron en el puerto C, así que imputaremos ese valor a ambas mujeres:

```{r}
full[full$Embarked=="",]$Embarked <- "C"
train[train$Embarked=="",]$Embarked <- "C"
```

### Fare

De las tarifas de los pasajes encontramos que tan solo hay un caso donde desconocemos el precio que se pagó:

```{r}
full[is.na(full$Fare),]
```

De nuevo vamos a observar cuanto costaron estos pasajes observando el puerto de embarcación y la clase a la que pertenece este pasajero

```{r}
ggplot(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,], aes(x=Fare)) +   
  geom_density(color="darkblue", fill="lightblue",size=1)+ylab("Densidad")+xlab("Precio del pasaje") + 
  geom_vline(xintercept = median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare),color="red",size=1.1,linetype="dashed") + 
  geom_vline(xintercept = mean(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare),color="green",size=1.1,linetype="dashed") +
  annotate(geom = "text", label = c("Mediana", "Media"), x = c(median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare), mean(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)), y = c(0.05, 0.05), angle = 90, vjust = 1)
```

Viendo la distribución de los datos vemos que lo más correcto sería coger la mediana del precio del pasaje, que en este caso es `r median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)`

```{r}
fare_median <-  median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)

full[is.na(full$Fare),]$Fare <- fare_median
test[is.na(test$Fare),]$Fare <- fare_median
```

Por otro lado tenemos registros donde el precio del pasaje fue cero

```{r}
full[full$Fare == 0,]
```

Haciendo una busqueda por internet de los nombres de algunas de estas personas vemos algo que podíamos sopechar: eran parte de los trabajadores de la embarcación o relacionados con ésta (como el propio diseñador del Titanic, Roderick Robert Crispin).

Puesto que realmente el pasaje no valía cero dolares sino que estas personas fueron invitadas, lo que vamos a hacer para que ésto no desvirtue los datos es imputar de nuevo la median, en este caso lo haremos según la clase de pasaje que tuvieran (todos eran del puerto de embarcación S)

```{r}
median_fare_1 <- median(full[full$Fare != 0 & full$Pclass == 1 & full$Embarked == 'S',]$Fare)
median_fare_2 <- median(full[full$Fare != 0 & full$Pclass == 2 & full$Embarked == 'S',]$Fare)
median_fare_3 <- median(full[full$Fare != 0 & full$Pclass == 3 & full$Embarked == 'S',]$Fare)

#Imputamos según la clase en los dataset que hemos generado:
full[full$Fare == 0 & full$Pclass == 1,]$Fare <- median_fare_1
full[full$Fare == 0 & full$Pclass == 2,]$Fare <- median_fare_2
full[full$Fare == 0 & full$Pclass == 3,]$Fare <- median_fare_3

train[train$Fare == 0 & train$Pclass == 1,]$Fare <- median_fare_1
train[train$Fare == 0 & train$Pclass == 2,]$Fare <- median_fare_2
train[train$Fare == 0 & train$Pclass == 3,]$Fare <- median_fare_3

test[test$Fare == 0 & test$Pclass == 1,]$Fare <- median_fare_1

#Los siguientes casos no existen en el dataset de test: 
#test[test$Fare == 0 & test$Pclass == 2,]$Fare <- median_fare_2
#test[test$Fare == 0 & test$Pclass == 3,]$Fare <- median_fare_3

```

### Age

En la variable de edad encontramos que hay 177 NAs en el dataset de entrenamiento y 86 NAs en el de test.

La edad es una variable algo más complicada de imputar y una opción sería utilizar la mediana de la edad de los pasajeros, pero vamos a optar por utilizar el metodo kNN que nos imputará el valor de la edad utilizando los valores de los puntos más cercanos al que nos falta.

Las variables que tendremos en cuenta en esta imputación serán:

-   Sex
-   PClass
-   SibSp
-   Parch
-   Fare
-   Embarked

```{r}
full_imp <- kNN(full,k=11,dist_var=c('Sex','Pclass','SibSp','Fare','Parch','Embarked'),variable='Age')
```

Para ver si esta imputación ha afectado a la distribución de edad

```{r,warning=FALSE}

ggplot() + 
  geom_density(data=full_imp, aes(x=Age,color='Imputado') , size=1) + 
  geom_density(data=full, aes(x=Age, color = 'No imputado') ,size=1) + 
  geom_vline(xintercept = median(full$Age,na.rm = TRUE),color="blue",size=1.1,linetype="dashed") +
  geom_vline(xintercept = median(full_imp$Age),color="red",size=1.1,linetype="dashed") +
  ylab("Frecuencia") + xlab("Edad") + theme(legend.position = 'right') +
  scale_color_manual("DataSet",values = c('Imputado' = 'red', 'No imputado' = 'blue'))
  
```

Podemos ver un crecimiento en la densidad de valores alrededor de la mediana, pero la distribución sigue teniendo una forma parecida a la de ante de imputar valores, por lo que damos por correctos los datos que hemos introducido para los valores NA de la edad.

Por lo tanto pasamos ahora a imputar estos valores en los datasets que estamos ahora gestionando:

```{r, results='hide'}
full$Age <- full_imp$Age

train <- merge(train, full_imp[c('PassengerId','Age')], by.x=c("PassengerId"), by.y=c("PassengerId"), all.x=TRUE)
train <- train[,-which(names(train) %in% c("Age.x","PassengerId.y"))]
train <- train %>% rename( Age = Age.y )

test <- merge(test, full_imp[c('PassengerId','Age')], by.x=c("PassengerId"), by.y=c("PassengerId"), all.x=TRUE)
test <- test[,-which(names(test) %in% c("Age.x","PassengerId.y"))]
test <- test %>% rename( Age = Age.y )
```

## Outliers

Los valores extremos (o outliers) son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población. Hay diferentes métodos para identificar valores extremos, uno de ellos es mediante gráficos de cajas (boxplots), otros se basan en la distancia de Mahanlanobis o distancia de Cook, también se usan modelos estadísticos, supervisados o no supervisados, por ejemplo, mediante técnicas de clustering. En este caso utilizaremos la función boxplots.stats() de R.

```{r, results='hide'}
borrar<-c("PassengerId","Name","Ticket","Pclass","Embarked","Survived","Sex","Cabin" )
fullr<-full[,!names(full) %in% borrar]
boxplot(fullr, col=rainbow(ncol(fullr)))

```

Revisando los valores extremos de edad vemos que son valores válidos

```{r}
min(boxplot.stats(full$Age)$out)
max(boxplot.stats(full$Age)$out)
```

Para el fare (tarifa del pasajero) encontramos:

```{r}
min(boxplot.stats(full$Fare)$out)
max(boxplot.stats(full$Fare)$out)
```

Se ha buscado el rango de precios de los billetes (<https://www.20minutos.es/noticia/1365526/0/titanic/hundimiento/aniversario/>), y los precios máximosy mínimos están dentro del rango, con lo que se consideran valores válidos.

# Análisis de los datos

En primer lugar, se va a dividir el conjunto de entrenamiento en varios grupos para realizar el análisis de los datos y así poder estudiar la supervivencia.

## Selección de los grupos

Los grupos seleccionados serán los siguientes, para estudiar su relación con survived:

_Age_: se estudiará el efecto del rango de edad del pasajero en la supervivencia. 
_Embarked_: se analizará el efecto del puerto de embarque en la supervivencia. 
_Parch_: número de padres/madres, hijos/hijas a bordo del Titanic y su influencia. 
_Pclass_: se analizará la influencia de clase del pasajero. 
_Sex_: influencia del sexo del pasajero en la supervivencia. 
_SibSp_ y _Parch_: influencia del número de hermanos/hermanas, esposos/esposas a bordo del Titanic en la supervivencia.

Vamos a hacer un primer análisis descriptivo de cual podría ser la relacion entre estas variables y la probabilida de supervivencia de los pasajeros

```{r}
#Edad
train$GrupoEdad <- cut(train$Age, breaks = c(0,16,30,60,100), labels = c("Niños","Jóvenes","Adultos","Ancianos"))
train$Survived <- as.factor(train$Survived)
PGedad<-ggplot(train, aes(x=GrupoEdad, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

Pembarked <-ggplot(train, aes(x=Embarked, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

Pparch <-ggplot(train, aes(x=Parch, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PClase<-ggplot(train, aes(x=Pclass, fill=Survived)) + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PSexo<-ggplot(train, aes(x=Sex, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PSibSp <- ggplot(train, aes(x=SibSp, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')
```


```{r, figures-side, fig.show="hold", out.width="50%"}
PGedad
Pembarked
Pparch
PClase
PSexo
PSibSp
```


__Age__: Se aprecia que el porcentaje de supervivientes aumenta cuanto menor es la edad.

__Embarked__: Hay una menor tasa de supervivencia, de los pasajeros embarcados en Southampton y Queenstown con respecto a los embarcados en Cherbourg.

__Parch__: Parece ser que los pasajeros con 1 a 3 padres/hijos tenian más probabilidades de sobrevivir.

__Class__: La clase es una variable que impacta fuertemente sobre la tasa de supervivencia, siendo la tercera clase la más afectada por el accidente.

__Sex__: El sexo también impacta fuertemente sobre el índice de supervivencia, teniendo las mujeres más posibilidades de no morir.

__SibSp__: Parece que tener algún familiar puede aumentar tu probabilidad de sobrevivir, aunque ésta desciende conforme se tienen más familiares.


## Normalidad y homogeneidad de la varianza

__Normalidad__

Para verficar la suposición de la normalidad, utilizamos el test de Shapiro-Wilk, considerado uno de los métodos más potentes, en las variables númericas

| **Variable** | **p-value Shapiro Test** |   **Normalidad**   |
|:-------------------:|:-----------------:|:---------------:|
|   __Age__   |  ``r shapiro.test(train$Age)$p``  | Distribución normal | 
|   __Parch__  |  ``r shapiro.test(train$Parch)$p``  | Distribución normal | 
|   __Fare__  |  ``r shapiro.test(train$Fare)$p``  | Distribución normal |
|   __SibSp__  |  ``r shapiro.test(train$SibSp)$p``  | Distribución normal |
|   __Fare__  |  ``r shapiro.test(train$Fare)$p``  | Distribución normal |

Se encuentra en todos los casos que el p-value es menor a 0.05, con lo que todos siguen una distribución normal.

__Homocedasticidad__

Para el estudio de la homocedasticidad usamos el estadístico F, que se puede aplicar con la función _var.test()_. Lo aplicaremos para unos grupos a modo de ejemplo

```{r}
var.test(x=train[train$Embarked=='S','Fare'],y=train[train$Embarked=='C','Fare'])
```

Al comparar los precios de los billetes de los puertos de embarque S y C encontramos que hay una diferencia significativa entre las varianzas de los dos grupos. 

Podemos aplicar este mismo test para tratar de encontrar si hay homogeneidad en la varianza para los sexos en la variable de edad 

```{r}
var.test(x=train[train$Sex=='male','Age'],y=train[train$Sex=='female','Age'])
```

En este caso encontramos que las varianzas no muestran diferencias significativas entre sexos.


## Comparación de grupos

### Correlación entre variables 

Nos interesa saber si hay posibles relaciones entre las variables que estamos teniendo en cuenta, por lo que haremos un calculo de la matriz de correlación para las variables númericas

```{r,include=FALSE}
train$Survived <- as.numeric(train$Survived)
train$Pclass <- as.numeric(train$Pclass) 
```


```{r}
cor_table <- cor(train[,c("Survived","Pclass","SibSp","Parch","Fare","Age")],use = "complete.obs")
corrplot.mixed(cor_table,upper="circle",number.cex=.7,tl.cex=.8, title="Correlacion entre variables", mar=c(0,0,1,0))
```

```{r,include=FALSE}
train$Survived <- as.factor(train$Survived)
train$Pclass <- as.factor(train$Pclass) 
```


Vemos que hay una clara relación entre la clase del pasaje y el precio de éste, como era de esperar. 
La edad también influye en qué tipo de pasaje se compra, así como su precio. 

Otra relación que encontramos se da entre el numero de hijos-padres con hermanos-esposos, con un coeficiente de correlación de 0.38. De nuevo la edad vuelve a tener cierta importancia para estas variables. 

Finalmente vemos que hay una clara relación entre la clase de pasaje y el la probabilidad de sobrevivir al accidente del Titanic. 





### Grupo de Edad vs Supervivencia

Por el tipo de variables, se puede utilizar el test chi-cuadrado:

```{r}
temporal<-table(train$Survived, train$GrupoEdad)
plot(temporal, col=c("#9999FF","#CC66FF"), main="GrupoEdad vs Supervivientes")
chisq.test(temporal)
```
Dependencia: p-value es inferior a < 0,05, se rechaza la hipótesis nula de independencia con lo que la supervivencia depende del grupo de edad.

### Clase vs Supervivencia

Por el tipo de variables, también se puede utilizar el test chi-cuadrado:

```{r}
temporal<-table(train$Survived, train$Pclass)
plot(temporal, col=c("#9999FF","#CC66FF"), main="Clase vs Supervivientes")
chisq.test(temporal)
```
Dependencia: p-value es inferior a < 0,05, se rechaza la hipótesis nula de independencia con lo que la supervivencia depende de la clase a la que pertenece el ticket.

### Sexo vs Supervivencia

Por el tipo de variables, se puede utilizar el test chi-cuadrado:

```{r}
temporal2<-table(train$Survived, train$Sex)
plot(temporal2, col=c("#9999FF","#CC66FF"), main="Sexo vs Supervivencia")
chisq.test(temporal2)
```
Dependencia: p-value es inferior a < 0,05, se rechaza la hipótesis nula de independencia con lo que la supervivencia depende del sexo del pasajero.

### Tarifa vs Supervivencia

Se va a realizar una regresión lineal para aproximar la relación de dependencia lineal entre las dos variables, mediante la función lm().


datFare=lm( Survived ~ Fare, data=train)
summary(datFare)

Se aprecia un R-squared bajo, con lo que las variables no se correlacionan.

### Padres/madres, hijos e hijas vs Supervivencia

Se va a realizar una regresión lineal para aproximar la relación de dependencia lineal entre las dos variables, mediante la función lm().

datParch=lm( Survived ~ Parch, data=train)
summary(datParch)

A continuación, se va a ejecutar el test de ANOVA, para confirmar que la diferencia con y sin la variable, no es significativa.

```{r}
tieneParch <- glm(Survived ~ Parch, family = binomial(link='logit'), data = train)
summary(tieneParch)
anova(tieneParch, test="Chisq")

```

Se puede apreciar la desviación de residuales es prácticamente la misma sin la variable que con la variable (1186.7 vs 1180.8). La variable Parch no depende de la variable Survived.

### Métodos de clasificación


# Resultados y Conclusiones

Del estudio previo resulta que las variables Sex, Pclass y Age son las que tienen mayor relación con Survived.

```{r}
ggarrange(PSexo, PGedad, PClase, labels = c("S", "E", "C"), ncol = 1, nrow = 3)
```
Para evaluar la posibilidad de supervivencia, se van a crear diferentes modelos de predicción, para valorarlos a continuación.
En primer lugar se van a dividir de nuevo los datos para realizar el análisis
```{r}
set.seed(345)
```
Y se crean las diferentes regresiones:

Survived vs PClass + Sex + Age
Survived vs PClass + Sex
Survived vs PClass

```{r}
M0 <- glm( formula = Survived ~ Pclass + Sex + Age, data = train, family = binomial)
summary(M0)
M1 <- glm( formula = Survived ~ Pclass+ Sex, data = train, family = binomial)
summary(M1)
M3 <- glm( formula = Survived ~ Pclass, data = train, family = binomial)
summary(M3)
```
Con el Dato AIC, llegamos a la conclusión de que el primer modelo, con las tres variables, es el mejor, con lo que la supervivencia de los pasajeros depende del sexo, edad y clase.


