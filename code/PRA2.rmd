---
title: '**Práctica 2 - Limpieza y análisis de datos**'
author: "Maria Dolores Moyano Guerrero y Victor Cancer Castillo"
date: "25 de Mayo de 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    includes:
      in_header: logouoc.html
    toc: yes
    toc_float: yes
    toc_depth: 2
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,message=FALSE,warning=FALSE,results='hide',quietly = TRUE,include=FALSE}
library(ggplot2)
library(corrplot)
library(faraway)
library(ggfortify)
library(ResourceSelection)
library(pROC)
library(grid)
library(colorspace)
library(Rcpp)
library(vctrs)
library(tidyverse)
library(VIM)
library(ggpubr)
library(caTools)

```

------------------------------------------------------------------------

<font size="26"> **Titanic: Machine Learning from Disaster** </font>

------------------------------------------------------------------------

# Descripción del dataset

El desastre del RMS Titanic fue un accidente marítimo que acaeció en el 1912 y que se llevó por delante más de 1500 vidas. A bordo del Titanic iban más de 2000 pasajeros, por lo que cerca del 75% de los pasajerons fallecieron en el hundimiento del barco el cual no tenia botes salvavidas para todos los pasajeros.

Estas muertes no se dieron por igual para todos los grupos de pasajeros de manera aleatoria, sino que parece ser que hubo grupos dentro del barco que tuvieron más probabilidad de morir que otros, como podremos ver en este estudio.

Nos vamos a centrar aquí en tratar de averiguar qué características compartían en común los pasajeros que se salvaron/fallecieron para tratar de crear un modelo que sea capaz de predecir si un pasajero iba a morir o no.

# Integración y selección de los datos

Para tratar este problema vamos a utilizar los datos que se ofrecen en la competicción de [Kaggle](https://www.kaggle.com/competitions/titanic/overview), donde se da un dataset que contiene datos para entrenar el modelo y otro para hacer los tests del modelo creado.

Por un lado tenemos los datos para entrenar el modelo

```{r}
train <- read.table(file="train.csv",sep=',',dec='.',stringsAsFactors = TRUE,header=TRUE)
summary(train)
```

Y por otro tenemos los datos para testear dicho modelo

```{r}
test <- read.table(file="test.csv",sep=',',dec='.',stringsAsFactors = TRUE,header=TRUE)
```

Las variables que incluye el dataset son las siguientes:

-   *PassengerId*: Número de identificación del pasajero
-   *Survived*: Indica si el pasajero sobrevivió (0 = No, 1 = Sí)
-   *Pclass*: Clase de tiquet (1 = Primera clase, 2 = Segunda clase, 3 = Tercera clase)
-   *Name*: Nombre del pasajero
-   *Sex*: Sexo del pasajero
-   *Age*: Edad del pasajero
-   *SibSp*: Número de hermanos/hermanas, esposos/esposas a bordo del Titanic
-   *Parch*: Número de padres/madres, hijos/hijas a bordo del Titanic
-   *Ticket*: Número de ticket
-   *Fare*: Tarifa del pasajero
-   *Cabin*: Número de cabina
-   *Embarked*: Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton)

Para hacer análisis (no modelaje) trataremos los datos completos (es decir los datos de test y de entrenamiento, sin la columna *Survived*)

```{r}
full <- rbind(test,train[-which(names(train) == "Survived")])
```

# Limpieza de los datos

En primer lugar, vamos a estudiar si los datos tienen elementos vacíos

## Elementos nulos o ceros

### Embarked

Vemos entre los valores de la columna Embarked del dataset de entrenamiento que hay dos valores vacíos

```{r}
full[full$Embarked == "",]
```

Probablemente la relación más relevante entre el puerto de embarque la tiene el precio del billete (pues al hacer un viaje más largo se cobrará más al pasajero). Por lo tanto veamos con qué puerto encajan más estas dos pasajeras sabiendo que ellas pagaron 80\$ por su billete de primera clase:

```{r}
ggplot(full[full$Embarked != "" & full$Pclass == "1",],aes(x=Embarked,y=Fare, fill=Embarked)) + geom_boxplot()+
    theme(legend.position="none") + geom_hline(aes(yintercept=80), colour='yellow', linetype='dashed', lwd=2)

```

De esta gráfica podemos deducir que estas mujeres probablemente embarcaron en el puerto C, así que imputaremos ese valor a ambas mujeres:

```{r}
full[full$Embarked=="",]$Embarked <- "C"
train[train$Embarked=="",]$Embarked <- "C"
```

### Fare

De las tarifas de los pasajes encontramos que tan solo hay un caso donde desconocemos el precio que se pagó:

```{r}
full[is.na(full$Fare),]
```

De nuevo vamos a observar cuanto costaron estos pasajes observando el puerto de embarcación y la clase a la que pertenece este pasajero

```{r}
ggplot(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,], aes(x=Fare)) +   
  geom_density(color="darkblue", fill="lightblue",size=1)+ylab("Densidad")+xlab("Precio del pasaje") + 
  geom_vline(xintercept = median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare),color="red",size=1.1,linetype="dashed") + 
  geom_vline(xintercept = mean(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare),color="green",size=1.1,linetype="dashed") +
  annotate(geom = "text", label = c("Mediana", "Media"), x = c(median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare), mean(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)), y = c(0.05, 0.05), angle = 90, vjust = 1)
```

Viendo la distribución de los datos vemos que lo más correcto sería coger la mediana del precio del pasaje, que en este caso es `r median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)`

```{r}
fare_median <-  median(full[!is.na(full$Fare) & full$Pclass == "3" & full$Embarked == "S" ,]$Fare)

full[is.na(full$Fare),]$Fare <- fare_median
test[is.na(test$Fare),]$Fare <- fare_median
```

Por otro lado tenemos registros donde el precio del pasaje fue cero

```{r}
full[full$Fare == 0,]
```

Haciendo una busqueda por internet de los nombres de algunas de estas personas vemos algo que podíamos sopechar: eran parte de los trabajadores de la embarcación o relacionados con ésta (como el propio diseñador del Titanic, Roderick Robert Crispin).

Puesto que realmente el pasaje no valía cero dolares sino que estas personas fueron invitadas, lo que vamos a hacer para que ésto no desvirtue los datos es imputar de nuevo la median, en este caso lo haremos según la clase de pasaje que tuvieran (todos eran del puerto de embarcación S)

```{r}
median_fare_1 <- median(full[full$Fare != 0 & full$Pclass == 1 & full$Embarked == 'S',]$Fare)
median_fare_2 <- median(full[full$Fare != 0 & full$Pclass == 2 & full$Embarked == 'S',]$Fare)
median_fare_3 <- median(full[full$Fare != 0 & full$Pclass == 3 & full$Embarked == 'S',]$Fare)

#Imputamos según la clase en los dataset que hemos generado:
full[full$Fare == 0 & full$Pclass == 1,]$Fare <- median_fare_1
full[full$Fare == 0 & full$Pclass == 2,]$Fare <- median_fare_2
full[full$Fare == 0 & full$Pclass == 3,]$Fare <- median_fare_3

train[train$Fare == 0 & train$Pclass == 1,]$Fare <- median_fare_1
train[train$Fare == 0 & train$Pclass == 2,]$Fare <- median_fare_2
train[train$Fare == 0 & train$Pclass == 3,]$Fare <- median_fare_3

test[test$Fare == 0 & test$Pclass == 1,]$Fare <- median_fare_1

#Los siguientes casos no existen en el dataset de test: 
#test[test$Fare == 0 & test$Pclass == 2,]$Fare <- median_fare_2
#test[test$Fare == 0 & test$Pclass == 3,]$Fare <- median_fare_3

```

### Age

En la variable de edad encontramos que hay 177 NAs en el dataset de entrenamiento y 86 NAs en el de test.

La edad es una variable algo más complicada de imputar y una opción sería utilizar la mediana de la edad de los pasajeros, pero vamos a optar por utilizar el metodo kNN que nos imputará el valor de la edad utilizando los valores de los puntos más cercanos al que nos falta.

Las variables que tendremos en cuenta en esta imputación serán:

-   Sex
-   PClass
-   SibSp
-   Parch
-   Fare
-   Embarked

```{r}
full_imp <- kNN(full,k=11,dist_var=c('Sex','Pclass','SibSp','Fare','Parch','Embarked'),variable='Age')
```

Para ver si esta imputación ha afectado a la distribución de edad

```{r,warning=FALSE}

ggplot() + 
  geom_density(data=full_imp, aes(x=Age,color='Imputado') , size=1) + 
  geom_density(data=full, aes(x=Age, color = 'No imputado') ,size=1) + 
  geom_vline(xintercept = median(full$Age,na.rm = TRUE),color="blue",size=1.1,linetype="dashed") +
  geom_vline(xintercept = median(full_imp$Age),color="red",size=1.1,linetype="dashed") +
  ylab("Frecuencia") + xlab("Edad") + theme(legend.position = 'right') +
  scale_color_manual("DataSet",values = c('Imputado' = 'red', 'No imputado' = 'blue'))
  
```

Podemos ver un crecimiento en la densidad de valores alrededor de la mediana, pero la distribución sigue teniendo una forma parecida a la de ante de imputar valores, por lo que damos por correctos los datos que hemos introducido para los valores NA de la edad.

Por lo tanto pasamos ahora a imputar estos valores en los datasets que estamos ahora gestionando:

```{r, results='hide'}
full$Age <- full_imp$Age

train <- merge(train, full_imp[c('PassengerId','Age')], by.x=c("PassengerId"), by.y=c("PassengerId"), all.x=TRUE)
train <- train[,-which(names(train) %in% c("Age.x","PassengerId.y"))]
train <- train %>% rename( Age = Age.y )

test <- merge(test, full_imp[c('PassengerId','Age')], by.x=c("PassengerId"), by.y=c("PassengerId"), all.x=TRUE)
test <- test[,-which(names(test) %in% c("Age.x","PassengerId.y"))]
test <- test %>% rename( Age = Age.y )
```

## Outliers

Los valores extremos (o outliers) son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población. Hay diferentes métodos para identificar valores extremos, uno de ellos es mediante gráficos de cajas (boxplots), otros se basan en la distancia de Mahanlanobis o distancia de Cook, también se usan modelos estadísticos, supervisados o no supervisados, por ejemplo, mediante técnicas de clustering. En este caso utilizaremos la función boxplots.stats() de R.

```{r, results='hide'}
borrar<-c("PassengerId","Name","Ticket","Pclass","Embarked","Survived","Sex","Cabin" )
fullr<-full[,!names(full) %in% borrar]
boxplot(fullr, col=rainbow(ncol(fullr)))

```

Revisando los valores extremos de edad vemos que son valores válidos

```{r}
min(boxplot.stats(full$Age)$out)
max(boxplot.stats(full$Age)$out)
```

Para el fare (tarifa del pasajero) encontramos:

```{r}
min(boxplot.stats(full$Fare)$out)
max(boxplot.stats(full$Fare)$out)
```

Se ha buscado el rango de precios de los billetes (<https://www.20minutos.es/noticia/1365526/0/titanic/hundimiento/aniversario/>), y los precios máximosy mínimos están dentro del rango, con lo que se consideran valores válidos.

# Análisis de los datos

En primer lugar, se va a dividir el conjunto de entrenamiento en varios grupos para realizar el análisis de los datos y así poder estudiar la supervivencia.

## Selección de los grupos

Los grupos seleccionados serán los siguientes, para estudiar su relación con survived:

_Age_: se estudiará el efecto del rango de edad del pasajero en la supervivencia. 
_Embarked_: se analizará el efecto del puerto de embarque en la supervivencia. 
_Parch_: número de padres/madres, hijos/hijas a bordo del Titanic y su influencia. 
_Pclass_: se analizará la influencia de clase del pasajero. 
_Sex_: influencia del sexo del pasajero en la supervivencia. 
_SibSp_ y _Parch_: influencia del número de hermanos/hermanas, esposos/esposas a bordo del Titanic en la supervivencia.

Vamos a hacer un primer análisis descriptivo de cual podría ser la relacion entre estas variables y la probabilida de supervivencia de los pasajeros

```{r}
#Edad
train$GrupoEdad <- cut(train$Age, breaks = c(0,16,30,60,100), labels = c("Niños","Jóvenes","Adultos","Ancianos"))
train$Survived <- as.factor(train$Survived)
PGedad<-ggplot(train, aes(x=GrupoEdad, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

Pembarked <-ggplot(train, aes(x=Embarked, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

Pparch <-ggplot(train, aes(x=Parch, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PClase<-ggplot(train, aes(x=Pclass, fill=Survived)) + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PSexo<-ggplot(train, aes(x=Sex, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')

PSibSp <- ggplot(train, aes(x=SibSp, fill=Survived))  + geom_bar(position='fill') + ylab('Porcentaje de supervivientes')
```


```{r, figures-side, fig.show="hold", out.width="50%"}
PGedad
Pembarked
Pparch
PClase
PSexo
PSibSp
```


__Age__: Se aprecia que el porcentaje de supervivientes aumenta cuanto menor es la edad.

__Embarked__: Hay una menor tasa de supervivencia, de los pasajeros embarcados en Southampton y Queenstown con respecto a los embarcados en Cherbourg.

__Parch__: Parece ser que los pasajeros con 1 a 3 padres/hijos tenian más probabilidades de sobrevivir.

__Class__: La clase es una variable que impacta fuertemente sobre la tasa de supervivencia, siendo la tercera clase la más afectada por el accidente.

__Sex__: El sexo también impacta fuertemente sobre el índice de supervivencia, teniendo las mujeres más posibilidades de no morir.

__SibSp__: Parece que tener algún familiar puede aumentar tu probabilidad de sobrevivir, aunque ésta desciende conforme se tienen más familiares.


## Normalidad y homogeneidad de la varianza

__Normalidad__

Para verficar la suposición de la normalidad, utilizamos el test de Shapiro-Wilk, considerado uno de los métodos más potentes, en las variables númericas

| **Variable** | **p-value Shapiro Test** |   **Normalidad**   |
|:-------------------:|:-----------------:|:---------------:|
|   __Age__   |  ``r round(shapiro.test(train$Age)$p,6)``  | Distribución normal | 
|   __Parch__  |  ``r round(shapiro.test(train$Parch)$p,6)``  | Distribución normal | 
|   __Fare__  |  ``r round(shapiro.test(train$Fare)$p,6)``  | Distribución normal |
|   __SibSp__  |  ``r round(shapiro.test(train$SibSp)$p,6)``  | Distribución normal |
|   __Fare__  |  ``r round(shapiro.test(train$Fare)$p,6)``  | Distribución normal |

Se encuentra en todos los casos que el p-value es menor a 0.05, con lo que todos siguen una distribución normal.

__Homocedasticidad__

Para el estudio de la homocedasticidad usamos el estadístico F, que se puede aplicar con la función _var.test()_. Lo aplicaremos para unos grupos a modo de ejemplo

```{r}
var.test(x=train[train$Embarked=='S','Fare'],y=train[train$Embarked=='C','Fare'])
```

Al comparar los precios de los billetes de los puertos de embarque S y C encontramos que hay una diferencia significativa entre las varianzas de los dos grupos. 

Podemos aplicar este mismo test para tratar de encontrar si hay homogeneidad en la varianza para los sexos en la variable de edad 

```{r}
var.test(x=train[train$Sex=='male','Age'],y=train[train$Sex=='female','Age'])
```

En este caso encontramos que las varianzas no muestran diferencias significativas entre sexos.


## Comparación de grupos

### Correlación entre variables 

Nos interesa saber si hay posibles relaciones entre las variables que estamos teniendo en cuenta, por lo que haremos un calculo de la matriz de correlación para las variables númericas

```{r,include=FALSE}
train$Survived_num <- as.numeric(train$Survived)
train$Pclass_num <- as.numeric(train$Pclass) 
```


```{r}
cor_table <- cor(train[,c("Survived_num","Pclass_num","SibSp","Parch","Fare","Age")],use = "complete.obs")
corrplot.mixed(cor_table,upper="circle",number.cex=.7,tl.cex=.8, title="Correlacion entre variables", mar=c(0,0,1,0))
```


Vemos que hay una clara relación entre la clase del pasaje y el precio de éste, como era de esperar. 
La edad también influye en qué tipo de pasaje se compra, así como su precio. 

Otra relación que encontramos se da entre el numero de hijos-padres con hermanos-esposos, con un coeficiente de correlación de 0.38. De nuevo la edad vuelve a tener cierta importancia para estas variables. 

Finalmente vemos que hay una clara relación entre la clase de pasaje y el la probabilidad de sobrevivir al accidente del Titanic. 


### Contraste de hipotesis

Nos planteamos la siguiente pregunta: ¿es el porcentaje de fallecidos más alto en el el grupo de tercera clase que en el resto de clases?

La hipotesis nula y alternativa son entonces: 

$$
H_0: p_{12} = p_3 \ ; \ H_1: p_{12} > p_3
$$

donde $p_{12}$ es la proporción de supervivivientes de clase uno y dos y $p_3$ es la de tercera clase. 

Puesto que nos hacemos la pregunta para inferir el valor en la población utilizando una muestra podemos asumir que la media va a seguir una distribución normal gracias al teorema del límite central. Podemos asumir lo mismo de la diferencia de las proporciones, $p_{12}-p_3$. 

Sin embargo desconocemos la varianza de la población ni si las varianzas entre grupos son iguales, por lo que vamos a utilizar la diferencia de las proporciones :

$$
z  = \frac{(\hat{p}_{12}-\hat{p}_3)-(p_{12}-p_3)}{\sqrt{\frac{p_{12}(1-p_{12})}{n_{12}}-\frac{p_3(1-p_3)}{n_3}}} \sim N(0,1)
$$

donde si se cumple la hipótesis nula, que es la hipótesis que queremos contrastar, tenemos $p_{12}=p_3=p$ y por lo tanto el estadístico de contraste es

$$
z = \frac{\hat{p}_{12}-\hat{p}_3}{\sqrt{\hat{p}(1-\hat{p})\left( \frac{1}{n_{12}}+ \frac{1}{n_3}\right)}} \ ; \ \hat{p} = \frac{n_{12}\, \hat{p}_{12}+n_3\,\hat{p}_3}{n_{12}+n_3}
$$

donde $\hat{p}$ es la estimación de la proporción poblacional común.

Vamos a definir nuestra propia función para llevar a cabo este análisis

```{r}
test_prop <- function(x,NC){
  
  p1 <- sum(x$Survived == 1 & x$Pclass== 3) / sum(x$Pclass== 3)
  p2 <- sum(x$Survived == 1 & x$Pclass!=3) / sum(x$Pclass!= 3)
  
  #Podemos calcular p sin necesidad de utilizar la formula de arriba
  p <- sum(x$Survived == 1) / nrow(x)
  
  n1 <- sum(x$Pclass== 3)
  n2 <- sum(x$Pclass!= 3)
  
  zobs <- (p1-p2)/sqrt(p*(1-p)*((1/n1)+(1/n2)))
  
  zcrit <- qnorm(1-NC/100, lower.tail=TRUE)
  pobs <- pnorm(zobs,lower.tail=TRUE)

  round(c(zobs,zcrit,pobs,p1,p2),5)
}

test_prop(train,97)

```

Por lo que concluimos con un nivel de confianza de 97% que un pasajero de tercera clase tiene más probabilidad de fallecer que si fuera de clase superior. Esto es debido a que $z_{obs}$ es mucho mejor a $z_{crit}$, o dicho de otra manera, encontramos un p-value enormemente pequeño, lo cual nos permite descartar la hipótesis nula.


### Regresión logística


Queremos crear un modelo de regresión para poder predecir si una persona del dataset de test ha sobrevivido o no. A partir de los gráficos del apartado anterior hemos visto clara una relación entre la variables Survived con Sex y Pclass, por lo que estas variables seguro entrarán en el modelo. 


```{r}
M0 <- glm( formula = Survived ~ Pclass + Sex, data = train, family=binomial(link=logit))
summary(M0)
```

Nos cuestionamos ahora si más variables podrían hacer mejorar el modelo, como por ejemplo el puerto de embarque

```{r}
M1 <- glm( formula = Survived ~ Pclass + Sex + Embarked, data = train, family=binomial(link=logit))
summary(M1)
```

vemos que el factor AIC (Akaike information criterion) ha disminuido, por lo que el modelo mejora. Además los coeficientes del resto de variables no se han visto afectados, lo cual podria indicar una correlación significativa entre las variables explicativas. 

Seguimos pues probando con más variables, en este caso el de la edad: 

```{r}
M2 <- glm( formula = Survived ~ Pclass + Sex + Embarked + Age, data = train, family=binomial(link=logit))
summary(M2)
```

vemos que el modelo vuelve a mejorar, disminuyendo el AIC. En este caso vemos que el coeficiente de Pclass ha decrecido, mostrando una relación entre clase y edad que ya vimos previamente. El cambio en el coeficiente no es suficientemente grande como para descartar la variable. 

Finalmente nos planteamos incluir también las variables SibSp y/o Parch. Hay una clara relación entre ambas variables por lo que incluir ambas quizás no es buena idea, veamos el AIC que nos dan cada una de ellas: 

```{r}
M3 <- glm( formula = Survived ~ Pclass + Sex + Embarked + Age + Parch , data = train, family=binomial(link=logit))
M3$aic
M4 <- glm( formula = Survived ~ Pclass + Sex + Embarked + Age + SibSp , data = train, family=binomial(link=logit))
M4$aic
M5 <- glm( formula = Survived ~ Pclass + Sex + Embarked + Age + Parch + SibSp, data = train, family=binomial(link=logit))
M5$aic
```

Efectivamente vemos que es mejor quedarse tan solo con la variable SibSp en este caso, por lo que descartamos la variable Parch. 

Para terminar, vamos a comprobar lo bien que funciona nuestra regresión con este mismo dataset (más adelante lo veremos con el de test) utilizando la curva ROC


```{r}
prob <- predict(M5, train, type="response")

r <- roc(train$Survived,prob,data=train)

plot (r)
```

Esta curva, contra más cerca está de la esquia superior izquierda está, menor es el error que está cometiendo. De hecho podemos extraer un valor númerico que nos dirá con mejor precisión lo bueno que es el modelo: 

```{r}
auc(r)
```

Vemos que tenemos un AUC de 0.86. Generalmente se dice que entre 0.6 y 0.8 el modelo se comporta de manera aceptable, pero por encima de 0.8 el modelo se ajusta bien a los datos que intenta reproducir. 

# Resultados y Conclusiones

Del estudio inicial resulta que las variables Sex, Pclass y Age son las que tienen mayor relación con Survived, puesto que hemos visto en las gráficas de supervivencia vs cada grupo cómo habia una clara relación entre estas variables. 

Hay variables que hemos desechado como el número de cabina o el nombre del pasajero puesto que hemos asumido que no tienen relación con la probabilidad de sobrevivir al accidente. Además hemos visto que hay una fuerte relación entre la clase del billete y el precio de éste, por lo que a la hora de proponer la regresión logística hemos decidido descartarla para el modelo.  

Haciendo una comparación entre los diferentes modelos de regresión logistica que hemos planteado hemos encontrado que el modelo que mejores resultados arrojaba era el que utilizaba las variables Pclass,  Sex, Embarked, Age y SibSp. 

Ahora que tenemos ya el modelo construido podemos finalmente participar en la competición propuesta en [Kaggle](https://www.kaggle.com/competitions/titanic/overview), por lo que vamos a aplicar nuestro modelo al dataset de test y extraer los valores predecidos para la variable Survived: 


```{r}
result <- predict(M5, test, type="response")
res_df <- data.frame(test$PassengerId,result)
#Si el resultado es menor a 0.5 le ponemos 0, sino 1
res_df$result_n <- ifelse(res_df$result < 0.5, 0,1)
res_df <- res_df %>% rename( PassengerId = test.PassengerId )
```

Para acabar pasamos a comparar nuestra predicción con los valores reales que se nos aportan en Kaggle para ver si nuestro modelo podría ser utilizado en la competición presentada 

```{r}
real_res <- read.table(file="gender_submission.csv",sep=',',dec='.',stringsAsFactors = TRUE,header=TRUE)
pred_vs_real <- merge(real_res,res_df, by=c("PassengerId"), all.x=TRUE)
```

La predicción de nuestro modelo ha acertado un ``r round(100*sum(pred_vs_real$Survived == pred_vs_real$result_n)/nrow(pred_vs_real),2)``% de los casos, lo cual consideramos es un resultado muy satisfactorio. 









